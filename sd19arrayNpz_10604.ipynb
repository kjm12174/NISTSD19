{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "nparray+np.savez_compressed(\"t.npz\", train_img=train_img) \n",
    "*read data from  /home/jmguo121/jm/MNIST_data/by_class/\n",
    "\n",
    "np.vstack-->label(train_lbl, val_lbl) is int  -->to avoid, ValueError: could not convert string to float: 'J'\n",
    "\n",
    "labels is --> 37-> 7\n",
    "(\n",
    "/by_class.zip係以hexadecimal ASCII representations命名影像資料夾，如4a-j,4b-k,30-0\n",
    "37-> 7\n",
    "/home/jmguo121/jm/MNIST_data/by_class/37/train_37/train_37_00505.png\n",
    ")\n",
    "\n",
    "image size=128x128\n",
    "\n",
    "Training vs validation\n",
    "/37/->77,704 個項目，大小為 51.0 MB\n",
    "/37/train_37/ -->35,796 個項目，大小為 21.2 MB  ;;the suggested training set for OCR studies\n",
    "37/hsf_4  --> 6,097 個項目，大小為 3.5 MB  ;; as a standard testing results reporting set\n",
    "Training vs validation ，6 vs 1\n",
    "(\n",
    "The train_30 files contains the “0”s of all writers of partitions hsf_{0,1,2,3,6,7}. The\n",
    "train_?? files comprise the suggested training set for OCR studies. The hsf_4 is likewise\n",
    "earmarked as a standard testing results reporting set. Note that the class files are redundant\n",
    "in this tree, since they contain only one unique hexadecimal class string, and the class has\n",
    "already been indicated in the parent directory name. \n",
    ")\n",
    "\n",
    "#train.npz,val.npz儲存影像,label,image mode & size \n",
    "'''\n",
    "from glob import glob\n",
    "from os.path import splitext\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import gzip\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tStart = time.time()#計時開始\n",
    "\n",
    "dataPath='/home/jmguo121/jm/MNIST_data/sd19_by_class/'   #sd-19 data path\n",
    "#image(PngImageFile mode=RGB size=128x128 (0, 255))  resized into 28x28 with grayscale value between 0 and 254\n",
    "rows, cols = 28, 28\n",
    "\n",
    "def prepareData(dataPath,rows, cols):\n",
    "        #將sd-19之train_,hsf_4資料夾png分別讀至一np array並存成壓縮檔sd-19train,sd-19val \n",
    "    train_img = np.zeros((rows, cols), dtype=np.float32)  #traning image for save npz file       \n",
    "    train_lbl= np.zeros(1, dtype=np.int8)  #training label\n",
    "    val_img= np.zeros((rows, cols), dtype=np.float32)   #validation image for save npz file \n",
    "    val_lbl= np.zeros(1, dtype=np.uint8)    #validation label\n",
    "\n",
    "    pnglist = glob( dataPath+\"*/*/*.png\" ) \n",
    "\n",
    "    def rgb2gray(rgb):  #png 3chanel-> gray 1chanel\n",
    "        r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "        gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        return gray  \n",
    "    \n",
    "    #如果png影像之npz已存在\n",
    "    try:\n",
    "        data = np.load(\"train.npz\") \n",
    "        train_img, train_lbl = data['train_img'], data['train_lbl'] \n",
    "        data = np.load(\"val.npz\")\n",
    "        val_img, val_lbl = data['val_img'], data['val_lbl'] \n",
    "        if train_img==[] or train_lbl==[] or val_img==[] or val_lbl==[]:\n",
    "            printprint(\"+npz壓縮檔有問題，將由sd19_by_clas夾讀取，並製作npz file\")  \n",
    "        else:  \n",
    "            print('成功讀取npz file, training image：'+ str(len(train_img))+', val_img:'+str(len(val_img)))\n",
    "            return train_img, train_lbl, val_img, val_lbl\n",
    "    except: \n",
    "        print(\"npz壓縮檔不存在，將由sd19_by_clas夾讀取，並製作npz file\")   \n",
    "    \n",
    "\n",
    "        #creat np array of image and label\n",
    "    i=0 \n",
    "    for png in pnglist: \n",
    "        if \"train\" in png:  #the suggested training set for OCR studies\n",
    "            im1=Image.open(png) \n",
    "            im2 = im1.resize((rows, cols), Image.NEAREST)      # use nearest neighbour filter to resize the image(28*28)\n",
    "            im2=np.array(im2) \n",
    "            im2=rgb2gray(im2)  #png 3chanel-> gray 1chanel \n",
    "            train_img=np.vstack((train_img,im2))  #is need:(( ));im2 加在 train_img後面\n",
    "            i1=png[len(dataPath):len(dataPath)+2] #取出label like '47'   \n",
    "            #train_lbl = np.vstack((train_lbl, chr(int(i1, 16))))  #16進位'47' --> 'G';;training label\n",
    "            train_lbl = np.append(train_lbl, int(i1, 16)) #training label;i1 加在train_lbl後面;16進位'47'(string) 代表'G'--> 轉成10進位的71,chr(71)-->'G'\n",
    "            i +=1\n",
    "        elif \"hsf_4\" in png:    #validation data; hsf_4 standard testing set\n",
    "            im1=Image.open(png) \n",
    "            im2 = im1.resize((rows, cols), Image.NEAREST)      # use nearest neighbour filter to resize the image(28*28)\n",
    "            im2=np.array(im2)\n",
    "            im2=rgb2gray(im2)  #png 3chanel-> gray 1chanel\n",
    "            val_img=np.vstack((val_img,im2))  #validation image;im2加在val_img後面\n",
    "            i1=png[len(dataPath):len(dataPath)+2] #取出label like '47'    \n",
    "            #val_lbl = np.vstack((val_lbl, chr(int(i1, 16))))  #16進位'47' --> 'G'\n",
    "            val_lbl = np.append(val_lbl, int(i1, 16)) #validation label;i1加在val_lbl後面;16進位'47'(string) 代表'G'--> 轉成10進位的71,chr(71)-->'G'\n",
    "            i +=1 \n",
    "            \n",
    "        if((i%500)==0):\n",
    "            print('已讀取：'+ str(i) +'---'+png[len(dataPath):len(png)]+'\\r',end='')\n",
    " \n",
    "    if train_img==[] or train_lbl==[] or val_img==[] or val_lbl==[]:\n",
    "        print(\"無資料\")\n",
    "        return 0\n",
    "    #儲存影像,label,image mode & size\n",
    "    print(len(train_lbl),train_lbl.shape, len(train_img),train_img.shape)\n",
    "    #im={'mode':im2.mode,'size':im2.size}\n",
    "    train_img=train_img.reshape((len(train_lbl),28, 28))\n",
    "    train_img=np.delete(train_img, 0,0)  #del 空的初值\n",
    "    train_lbl=np.delete(train_lbl, 0,0)  #del 空的初值\n",
    "    val_img=val_img.reshape((len(val_lbl),28, 28))\n",
    "    val_img=np.delete(val_img, 0,0)  #del 空的初值\n",
    "    val_lbl=np.delete(val_lbl, 0,0)  #del 空的初值\n",
    "    np.savez_compressed(\"train.npz\", train_img=train_img, train_lbl=train_lbl)    \n",
    "    np.savez_compressed(\"val.npz\", val_img=val_img, val_lbl=val_lbl) \n",
    "    print('成功讀取npz file, training image：'+ str(len(train_img))+', val_img1:'+str(len(val_img)))\n",
    "    return train_img, train_lbl, val_img, val_lbl  \n",
    "\n",
    "#將sd19之png images、labe、image mode & size等匯集成list\n",
    "train_img, train_lbl, val_img, val_lbl = prepareData(dataPath, rows, cols)  \n",
    "   \n",
    "tEnd = time.time()#計時結束\n",
    "m, s = divmod((tEnd - tStart), 60) \n",
    "h, m = divmod(m, 60) \n",
    "print('')\n",
    "print (\"it cost: %02d:%02d:%02d\" % (h, m, s)) \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(train_img[i], cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print(type(train_lbl),type(train_lbl[0]), train_lbl.shape,train_lbl[0:10])\n",
    "\n",
    "\n",
    "import mxnet as mx\n",
    "def to4d(img):\n",
    "    return img.reshape(img.shape[0], 1, 28, 28).astype(np.float32)/255\n",
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(to4d(train_img), train_lbl, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(to4d(val_img), val_lbl, batch_size)\n",
    "\n",
    "\n",
    "# Create a place holder variable for the input data\n",
    "data = mx.sym.Variable('data')\n",
    "# Flatten the data from 4-D shape (batch_size, num_channel, width, height) \n",
    "# into 2-D (batch_size, num_channel*width*height)\n",
    "data = mx.sym.Flatten(data=data)\n",
    "\n",
    "# The first fully-connected layer\n",
    "fc1  = mx.sym.FullyConnected(data=data, name='fc1', num_hidden=128)\n",
    "# Apply relu to the output of the first fully-connnected layer\n",
    "act1 = mx.sym.Activation(data=fc1, name='relu1', act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the according activation function\n",
    "fc2  = mx.sym.FullyConnected(data=act1, name='fc2', num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, name='relu2', act_type=\"relu\")\n",
    "\n",
    "# The thrid fully-connected layer, note that the hidden size should be 10, which is the number of unique digits\n",
    "fc3  = mx.sym.FullyConnected(data=act2, name='fc3', num_hidden=62)  #num_hidden=10\n",
    "# The softmax and loss layer\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')\n",
    "\n",
    "# We visualize the network structure with output size (the batch_size is ignored.)\n",
    "shape = {\"data\" : (batch_size, 1, 28, 28)}\n",
    "mx.viz.plot_network(symbol=mlp, shape=shape)\n",
    "\n",
    "\n",
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "model = mx.model.FeedForward(\n",
    "    symbol = mlp,       # network structure\n",
    "    num_epoch = 10,     # number of data passes for training \n",
    "    learning_rate = 0.1 # learning rate of SGD \n",
    ")\n",
    "model.fit(\n",
    "    X=train_iter,       # training data\n",
    "    eval_data=val_iter, # validation data\n",
    "    batch_end_callback = mx.callback.Speedometer(batch_size, 200) # output progress for each 200 data batches\n",
    ")\n",
    "\n",
    "tEnd = time.time()#計時結束\n",
    "m, s = divmod((tEnd - tStart), 60) \n",
    "h, m = divmod(m, 60) \n",
    "print('')\n",
    "print (\"training cost: %02d:%02d:%02d\" % (h, m, s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npz壓縮檔不存在，將由sd19_by_clas夾讀取，並製作npz file\n",
      "已讀取：264000---30/train_30/train_30_26984.png\r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "nparray+np.savez_compressed(\"t.npz\", train_img=train_img) \n",
    "*read data from  /home/jmguo121/jm/MNIST_data/by_class/\n",
    "\n",
    "np.vstack-->label(train_lbl, val_lbl) is int  -->to avoid, ValueError: could not convert string to float: 'J'\n",
    "\n",
    "labels is --> 37-> 7\n",
    "(\n",
    "/by_class.zip係以hexadecimal ASCII representations命名影像資料夾，如4a-j,4b-k,30-0\n",
    "37-> 7\n",
    "/home/jmguo121/jm/MNIST_data/by_class/37/train_37/train_37_00505.png\n",
    ")\n",
    "\n",
    "image size=128x128\n",
    "\n",
    "Training vs validation\n",
    "/37/->77,704 個項目，大小為 51.0 MB\n",
    "/37/train_37/ -->35,796 個項目，大小為 21.2 MB  ;;the suggested training set for OCR studies\n",
    "37/hsf_4  --> 6,097 個項目，大小為 3.5 MB  ;; as a standard testing results reporting set\n",
    "Training vs validation ，6 vs 1\n",
    "(\n",
    "The train_30 files contains the “0”s of all writers of partitions hsf_{0,1,2,3,6,7}. The\n",
    "train_?? files comprise the suggested training set for OCR studies. The hsf_4 is likewise\n",
    "earmarked as a standard testing results reporting set. Note that the class files are redundant\n",
    "in this tree, since they contain only one unique hexadecimal class string, and the class has\n",
    "already been indicated in the parent directory name. \n",
    ")\n",
    "\n",
    "#train.npz,val.npz儲存影像,label,image mode & size \n",
    "'''\n",
    "from glob import glob\n",
    "from os.path import splitext\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import gzip\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tStart = time.time()#計時開始\n",
    "\n",
    "dataPath='/home/jmguo121/jm/MNIST_data/sd19_by_class/'   #sd-19 data path\n",
    "#image(PngImageFile mode=RGB size=128x128 (0, 255))  resized into 28x28 with grayscale value between 0 and 254\n",
    "rows, cols = 28, 28\n",
    "\n",
    "def prepareData(dataPath,rows, cols):\n",
    "        #將sd-19之train_,hsf_4資料夾png分別讀至一np array並存成壓縮檔sd-19train,sd-19val \n",
    "    train_img = np.zeros((rows, cols), dtype=np.float32)  #traning image for save npz file       \n",
    "    train_lbl= np.zeros(1, dtype=np.int8)  #training label\n",
    "    val_img= np.zeros((rows, cols), dtype=np.float32)   #validation image for save npz file \n",
    "    val_lbl= np.zeros(1, dtype=np.uint8)    #validation label\n",
    "\n",
    "    pnglist = glob( dataPath+\"*/*/*.png\" ) \n",
    "\n",
    "    def rgb2gray(rgb):  #png 3chanel-> gray 1chanel\n",
    "        r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "        gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        return gray  \n",
    "    \n",
    "    #如果png影像之npz已存在\n",
    "    try:\n",
    "        data = np.load(\"train.npz\") \n",
    "        train_img, train_lbl = data['train_img'], data['train_lbl'] \n",
    "        data = np.load(\"val.npz\")\n",
    "        val_img, val_lbl = data['val_img'], data['val_lbl'] \n",
    "        if train_img==[] or train_lbl==[] or val_img==[] or val_lbl==[]:\n",
    "            printprint(\"+npz壓縮檔有問題，將由sd19_by_clas夾讀取，並製作npz file\")  \n",
    "        else:  \n",
    "            print('成功讀取npz file, training image：'+ str(len(train_img))+', val_img:'+str(len(val_img)))\n",
    "            return train_img, train_lbl, val_img, val_lbl\n",
    "    except: \n",
    "        print(\"npz壓縮檔不存在，將由sd19_by_clas夾讀取，並製作npz file\")   \n",
    "    \n",
    "\n",
    "        #creat np array of image and label\n",
    "    i=0 \n",
    "    for png in pnglist: \n",
    "        if \"train\" in png:  #the suggested training set for OCR studies\n",
    "            im1=Image.open(png) \n",
    "            im2 = im1.resize((rows, cols), Image.NEAREST)      # use nearest neighbour filter to resize the image(28*28)\n",
    "            im2=np.array(im2) \n",
    "            im2=rgb2gray(im2)  #png 3chanel-> gray 1chanel \n",
    "            train_img=np.vstack((train_img,im2))  #is need:(( ));im2 加在 train_img後面\n",
    "            i1=png[len(dataPath):len(dataPath)+2] #取出label like '47'   \n",
    "            #train_lbl = np.vstack((train_lbl, chr(int(i1, 16))))  #16進位'47' --> 'G';;training label\n",
    "            train_lbl = np.append(train_lbl, int(i1, 16)) #training label;i1 加在train_lbl後面;16進位'47'(string) 代表'G'--> 轉成10進位的71,chr(71)-->'G'\n",
    "            i +=1\n",
    "        elif \"hsf_4\" in png:    #validation data; hsf_4 standard testing set\n",
    "            im1=Image.open(png) \n",
    "            im2 = im1.resize((rows, cols), Image.NEAREST)      # use nearest neighbour filter to resize the image(28*28)\n",
    "            im2=np.array(im2)\n",
    "            im2=rgb2gray(im2)  #png 3chanel-> gray 1chanel\n",
    "            val_img=np.vstack((val_img,im2))  #validation image;im2加在val_img後面\n",
    "            i1=png[len(dataPath):len(dataPath)+2] #取出label like '47'    \n",
    "            #val_lbl = np.vstack((val_lbl, chr(int(i1, 16))))  #16進位'47' --> 'G'\n",
    "            val_lbl = np.append(val_lbl, int(i1, 16)) #validation label;i1加在val_lbl後面;16進位'47'(string) 代表'G'--> 轉成10進位的71,chr(71)-->'G'\n",
    "            i +=1 \n",
    "            \n",
    "        if((i%500)==0):\n",
    "            print('已讀取：'+ str(i) +'---'+png[len(dataPath):len(png)]+'\\r',end='')\n",
    " \n",
    "    if train_img==[] or train_lbl==[] or val_img==[] or val_lbl==[]:\n",
    "        print(\"無資料\")\n",
    "        return 0\n",
    "    #儲存影像,label,image mode & size\n",
    "    print(len(train_lbl),train_lbl.shape, len(train_img),train_img.shape)\n",
    "    #im={'mode':im2.mode,'size':im2.size}\n",
    "    train_img=train_img.reshape((len(train_lbl),28, 28))\n",
    "    train_img=np.delete(train_img, 0,0)  #del 空的初值\n",
    "    train_lbl=np.delete(train_lbl, 0,0)  #del 空的初值\n",
    "    val_img=val_img.reshape((len(val_lbl),28, 28))\n",
    "    val_img=np.delete(val_img, 0,0)  #del 空的初值\n",
    "    val_lbl=np.delete(val_lbl, 0,0)  #del 空的初值\n",
    "    np.savez_compressed(\"train.npz\", train_img=train_img, train_lbl=train_lbl)    \n",
    "    np.savez_compressed(\"val.npz\", val_img=val_img, val_lbl=val_lbl) \n",
    "    print('成功讀取npz file, training image：'+ str(len(train_img))+', val_img1:'+str(len(val_img)))\n",
    "    return train_img, train_lbl, val_img, val_lbl  \n",
    "\n",
    "#將sd19之png images、labe、image mode & size等匯集成list\n",
    "train_img, train_lbl, val_img, val_lbl = prepareData(dataPath, rows, cols)  \n",
    "   \n",
    "tEnd = time.time()#計時結束\n",
    "m, s = divmod((tEnd - tStart), 60)  \n",
    "h, m = divmod(m, 60) \n",
    "print('')\n",
    "print (\"it cost: %02d:%02d:%02d\" % (h, m, s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]] [1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([[1,2],[3,4]])\n",
    "b=np.array([[5,6],[7,8]])\n",
    "c=np.vstack((a,b))\n",
    "c1=np.append(a,5)\n",
    "print(c,c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAA/CAYAAADwizNIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAn1JREFUeJzt3d1um0AUhVFT9f1fmVxErsHFLo3MnMNmLSk3vSgTmPn4\nCZaneZ5vAJzfr+oBAPAZgg4QQtABQgg6QAhBBwgh6AAhBB0ghKADhBB0gBC/B2+v4mOp08a/Gcea\ncawZx5pxrHUZx19coQOEEHSAEIIOEELQAUIIOkAIQQcIIeh8zDTterOKQRyPnqZp+vPzaaPfQ+cg\ny8lx9LdQCQW8V7VGBL2p/50Q94gfPZFe/f+VX2W4Nabqr1acpql8DPR2xPwQ9KaWB/tdpJ8nxdER\n2RrX6HCd5Q5B1B9GzpU98yN1nZwi6FXh6OL59z5L0I60vCO56rxg2zzP/1wjqfPmFEG/qzwII59R\n79VlHKOd5feunqvd9tPI8Ww9gqzaH3tOMJ/iLZedui0OHo56Y4CfcSzqCPpOlZN0uW2LZa3jifbK\nx2jrLnrknfXVT+6CDhDiVM/Qr6jjK3l3/jD52qjPAnTe71e+Uq7SOujPE6Jy8nZaOGdYzEfrEovl\nsRg5plfb63Jyrf5jZPX2q7R+5DLP8+rnit69Z17xvLBLSLup2C+jTyJ7LU9yo9dtx06MPEatr9D5\ntly4W4tk9FXZfXuVMemycEd9QvedLlflt9tjrl75brpyLgj6SbwLR9X7vdULp5PKd5xvt16P4TqM\nodLzxc7I/SHoJ9NlsXQZB98cj16qjkfrZ+gA7CfoACEEHSCEoAOEEHSAEIIOEELQAUJM3l8FyOAK\nHSCEoAOEEHSAEIIOEELQAUIIOkAIQQcIIegAIQQdIISgA4QQdIAQgg4QQtABQgg6QAhBBwgh6AAh\nBB0ghKADhBB0gBCCDhBC0AFCCDpACEEHCPEFtIgMe/kbkp0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec81205978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.int64'> (3962,) [74 74 74 74 74 74 74 74 74 74]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(train_img[i], cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print(type(train_lbl),type(train_lbl[0]), train_lbl.shape,train_lbl[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def to4d(img):\n",
    "    return img.reshape(img.shape[0], 1, 28, 28).astype(np.float32)/255\n",
    "\n",
    "batch_size = 100\n",
    "train_iter = mx.io.NDArrayIter(to4d(train_img), train_lbl, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(to4d(val_img), val_lbl, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: plot Pages: 1 -->\n",
       "<svg width=\"214pt\" height=\"829pt\"\n",
       " viewBox=\"0.00 0.00 214.00 829.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 825)\">\n",
       "<title>plot</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-825 210,-825 210,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\"><title>data</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"47\" cy=\"-29\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-25.3\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- flatten1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>flatten1</title>\n",
       "<polygon fill=\"#fdb462\" stroke=\"black\" points=\"94,-167 -7.10543e-15,-167 -7.10543e-15,-109 94,-109 94,-167\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\">Flatten</text>\n",
       "</g>\n",
       "<!-- flatten1&#45;&gt;data -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>flatten1&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-98.5824C47,-85.2841 47,-70.632 47,-58.2967\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-108.887 42.5001,-98.887 47,-103.887 47.0001,-98.887 47.0001,-98.887 47.0001,-98.887 47,-103.887 51.5001,-98.8871 47,-108.887 47,-108.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"71\" y=\"-79.8\" font-family=\"Times,serif\" font-size=\"14.00\">1x28x28</text>\n",
       "</g>\n",
       "<!-- fc1 -->\n",
       "<g id=\"node3\" class=\"node\"><title>fc1</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-276 -7.10543e-15,-276 -7.10543e-15,-218 94,-218 94,-276\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-250.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-235.8\" font-family=\"Times,serif\" font-size=\"14.00\">128</text>\n",
       "</g>\n",
       "<!-- fc1&#45;&gt;flatten1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>fc1&#45;&gt;flatten1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-207.582C47,-194.284 47,-179.632 47,-167.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-217.887 42.5001,-207.887 47,-212.887 47.0001,-207.887 47.0001,-207.887 47.0001,-207.887 47,-212.887 51.5001,-207.887 47,-217.887 47,-217.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-188.8\" font-family=\"Times,serif\" font-size=\"14.00\">784</text>\n",
       "</g>\n",
       "<!-- relu1 -->\n",
       "<g id=\"node4\" class=\"node\"><title>relu1</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"94,-385 -7.10543e-15,-385 -7.10543e-15,-327 94,-327 94,-385\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-359.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-344.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- relu1&#45;&gt;fc1 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>relu1&#45;&gt;fc1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-316.582C47,-303.284 47,-288.632 47,-276.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-326.887 42.5001,-316.887 47,-321.887 47.0001,-316.887 47.0001,-316.887 47.0001,-316.887 47,-321.887 51.5001,-316.887 47,-326.887 47,-326.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-297.8\" font-family=\"Times,serif\" font-size=\"14.00\">128</text>\n",
       "</g>\n",
       "<!-- fc2 -->\n",
       "<g id=\"node5\" class=\"node\"><title>fc2</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-494 -7.10543e-15,-494 -7.10543e-15,-436 94,-436 94,-494\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-468.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-453.8\" font-family=\"Times,serif\" font-size=\"14.00\">64</text>\n",
       "</g>\n",
       "<!-- fc2&#45;&gt;relu1 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>fc2&#45;&gt;relu1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-425.582C47,-412.284 47,-397.632 47,-385.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-435.887 42.5001,-425.887 47,-430.887 47.0001,-425.887 47.0001,-425.887 47.0001,-425.887 47,-430.887 51.5001,-425.887 47,-435.887 47,-435.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"57.5\" y=\"-406.8\" font-family=\"Times,serif\" font-size=\"14.00\">128</text>\n",
       "</g>\n",
       "<!-- relu2 -->\n",
       "<g id=\"node6\" class=\"node\"><title>relu2</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"94,-603 -7.10543e-15,-603 -7.10543e-15,-545 94,-545 94,-603\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-577.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-562.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- relu2&#45;&gt;fc2 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>relu2&#45;&gt;fc2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-534.582C47,-521.284 47,-506.632 47,-494.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-544.887 42.5001,-534.887 47,-539.887 47.0001,-534.887 47.0001,-534.887 47.0001,-534.887 47,-539.887 51.5001,-534.887 47,-544.887 47,-544.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-515.8\" font-family=\"Times,serif\" font-size=\"14.00\">64</text>\n",
       "</g>\n",
       "<!-- fc3 -->\n",
       "<g id=\"node7\" class=\"node\"><title>fc3</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-712 -7.10543e-15,-712 -7.10543e-15,-654 94,-654 94,-712\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-686.8\" font-family=\"Times,serif\" font-size=\"14.00\">FullyConnected</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-671.8\" font-family=\"Times,serif\" font-size=\"14.00\">62</text>\n",
       "</g>\n",
       "<!-- fc3&#45;&gt;relu2 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>fc3&#45;&gt;relu2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-643.582C47,-630.284 47,-615.632 47,-603.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-653.887 42.5001,-643.887 47,-648.887 47.0001,-643.887 47.0001,-643.887 47.0001,-643.887 47,-648.887 51.5001,-643.887 47,-653.887 47,-653.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-624.8\" font-family=\"Times,serif\" font-size=\"14.00\">64</text>\n",
       "</g>\n",
       "<!-- softmax_label -->\n",
       "<g id=\"node8\" class=\"node\"><title>softmax_label</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"159\" cy=\"-683\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-679.3\" font-family=\"Times,serif\" font-size=\"14.00\">softmax_label</text>\n",
       "</g>\n",
       "<!-- softmax -->\n",
       "<g id=\"node9\" class=\"node\"><title>softmax</title>\n",
       "<polygon fill=\"#fccde5\" stroke=\"black\" points=\"170,-821 76,-821 76,-763 170,-763 170,-821\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-788.3\" font-family=\"Times,serif\" font-size=\"14.00\">SoftmaxOutput</text>\n",
       "</g>\n",
       "<!-- softmax&#45;&gt;fc3 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>softmax&#45;&gt;fc3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.1082,-754.547C87.3017,-740.741 76.2938,-725.243 67.0986,-712.297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.032,-762.887 93.5724,-757.34 100.137,-758.811 97.2411,-754.734 97.2411,-754.734 97.2411,-754.734 100.137,-758.811 100.91,-752.128 103.032,-762.887 103.032,-762.887\"/>\n",
       "<text text-anchor=\"middle\" x=\"97\" y=\"-733.8\" font-family=\"Times,serif\" font-size=\"14.00\">62</text>\n",
       "</g>\n",
       "<!-- softmax&#45;&gt;softmax_label -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>softmax&#45;&gt;softmax_label</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M135.713,-753.215C140.333,-739.483 145.463,-724.236 149.729,-711.555\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.459,-762.887 131.382,-751.974 134.053,-758.148 135.647,-753.409 135.647,-753.409 135.647,-753.409 134.053,-758.148 139.913,-754.844 132.459,-762.887 132.459,-762.887\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fec5874ef60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a place holder variable for the input data\n",
    "data = mx.sym.Variable('data')\n",
    "# Flatten the data from 4-D shape (batch_size, num_channel, width, height) \n",
    "# into 2-D (batch_size, num_channel*width*height)\n",
    "data = mx.sym.Flatten(data=data)\n",
    "\n",
    "# The first fully-connected layer\n",
    "fc1  = mx.sym.FullyConnected(data=data, name='fc1', num_hidden=128)\n",
    "# Apply relu to the output of the first fully-connnected layer\n",
    "act1 = mx.sym.Activation(data=fc1, name='relu1', act_type=\"relu\")\n",
    "\n",
    "# The second fully-connected layer and the according activation function\n",
    "fc2  = mx.sym.FullyConnected(data=act1, name='fc2', num_hidden = 64)\n",
    "act2 = mx.sym.Activation(data=fc2, name='relu2', act_type=\"relu\")\n",
    "\n",
    "# The thrid fully-connected layer, note that the hidden size should be 10, which is the number of unique digits\n",
    "fc3  = mx.sym.FullyConnected(data=act2, name='fc3', num_hidden=62)  #num_hidden=10\n",
    "# The softmax and loss layer\n",
    "mlp  = mx.sym.SoftmaxOutput(data=fc3, name='softmax')\n",
    "\n",
    "# We visualize the network structure with output size (the batch_size is ignored.)\n",
    "shape = {\"data\" : (batch_size, 1, 28, 28)}\n",
    "mx.viz.plot_network(symbol=mlp, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start training with [cpu(0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[Deprecation Warning] mxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Resetting Data Iterator\n",
      "INFO:root:Epoch[0] Time cost=1.378\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.000000\n",
      "INFO:root:Epoch[1] Resetting Data Iterator\n",
      "INFO:root:Epoch[1] Time cost=1.003\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.000000\n",
      "INFO:root:Epoch[2] Resetting Data Iterator\n",
      "INFO:root:Epoch[2] Time cost=1.315\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.000000\n",
      "INFO:root:Epoch[3] Resetting Data Iterator\n",
      "INFO:root:Epoch[3] Time cost=1.333\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.000000\n",
      "INFO:root:Epoch[4] Resetting Data Iterator\n",
      "INFO:root:Epoch[4] Time cost=0.870\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.000000\n",
      "INFO:root:Epoch[5] Resetting Data Iterator\n",
      "INFO:root:Epoch[5] Time cost=1.158\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.000000\n",
      "INFO:root:Epoch[6] Resetting Data Iterator\n",
      "INFO:root:Epoch[6] Time cost=0.985\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.000000\n",
      "INFO:root:Epoch[7] Resetting Data Iterator\n",
      "INFO:root:Epoch[7] Time cost=0.839\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.000000\n",
      "INFO:root:Epoch[8] Resetting Data Iterator\n",
      "INFO:root:Epoch[8] Time cost=1.733\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.000000\n",
      "INFO:root:Epoch[9] Resetting Data Iterator\n",
      "INFO:root:Epoch[9] Time cost=1.844\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.000000\n"
     ]
    }
   ],
   "source": [
    "# @@@ AUTOTEST_OUTPUT_IGNORED_CELL\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "model = mx.model.FeedForward(\n",
    "    symbol = mlp,       # network structure\n",
    "    num_epoch = 10,     # number of data passes for training \n",
    "    learning_rate = 0.1 # learning rate of SGD \n",
    ")\n",
    "model.fit(\n",
    "    X=train_iter,       # training data\n",
    "    eval_data=val_iter, # validation data\n",
    "    batch_end_callback = mx.callback.Speedometer(batch_size, 200) # output progress for each 200 data batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3963 (3963, 1) 110964 (110964, 28)g49.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmguo121/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:118: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功讀取npz file, training image：3962, val_img1:426\n",
      "\n",
      "it cost: 00:00:16\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "nparray+np.savez_compressed(\"t.npz\", train_img=train_img) \n",
    "*read data from  /home/jmguo121/jm/MNIST_data/by_class/\n",
    "\n",
    "np.vstack-->label(train_lbl, val_lbl) is int  -->to avoid, ValueError: could not convert string to float: 'J'\n",
    "\n",
    "labels is --> 37-> 7\n",
    "(\n",
    "/by_class.zip係以hexadecimal ASCII representations命名影像資料夾，如4a-j,4b-k,30-0\n",
    "37-> 7\n",
    "/home/jmguo121/jm/MNIST_data/by_class/37/train_37/train_37_00505.png\n",
    ")\n",
    "\n",
    "image size=128x128\n",
    "\n",
    "Training vs validation\n",
    "/37/->77,704 個項目，大小為 51.0 MB\n",
    "/37/train_37/ -->35,796 個項目，大小為 21.2 MB  ;;the suggested training set for OCR studies\n",
    "37/hsf_4  --> 6,097 個項目，大小為 3.5 MB  ;; as a standard testing results reporting set\n",
    "Training vs validation ，6 vs 1\n",
    "(\n",
    "The train_30 files contains the “0”s of all writers of partitions hsf_{0,1,2,3,6,7}. The\n",
    "train_?? files comprise the suggested training set for OCR studies. The hsf_4 is likewise\n",
    "earmarked as a standard testing results reporting set. Note that the class files are redundant\n",
    "in this tree, since they contain only one unique hexadecimal class string, and the class has\n",
    "already been indicated in the parent directory name. \n",
    ")\n",
    "\n",
    "#train.npz,val.npz儲存影像,label,image mode & size \n",
    "'''\n",
    "from glob import glob\n",
    "from os.path import splitext\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import gzip\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tStart = time.time()#計時開始\n",
    "\n",
    "dataPath='/home/jmguo121/jm/MNIST_data/sd19_by_class/'   #sd-19 data path\n",
    "#image(PngImageFile mode=RGB size=128x128 (0, 255))  resized into 28x28 with grayscale value between 0 and 254\n",
    "rows, cols = 28, 28\n",
    "\n",
    "def prepareData(dataPath,rows, cols):\n",
    "        #將sd-19之train_,hsf_4資料夾png分別讀至一np array並存成壓縮檔sd-19train,sd-19val \n",
    "    train_img = np.zeros((rows, cols), dtype=np.float32)  #traning image for save npz file       \n",
    "    train_lbl= np.zeros(1, dtype=np.int8)  #training label\n",
    "    val_img= np.zeros((rows, cols), dtype=np.float32)   #validation image for save npz file \n",
    "    val_lbl= np.zeros(1, dtype=np.uint8)    #validation label\n",
    "\n",
    "    pnglist = glob( dataPath+\"4a/*/*.png\" ) \n",
    "\n",
    "    def rgb2gray(rgb):  #png 3chanel-> gray 1chanel\n",
    "        r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "        gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        return gray \n",
    " \n",
    "    '''  \n",
    "    #如果png影像之npz已存在\n",
    "    try:\n",
    "        data = np.load(\"train.npz\") \n",
    "        train_img, train_lbl, im= data['train_img'], data['train_lbl'], data['im'].tolist()\n",
    "        data = np.load(\"val.npz\")\n",
    "        val_img, val_lbl, im = data['val_img'], data['val_lbl'] , data['im'].tolist()\n",
    "        if train_img==[] or train_lbl==[] or val_img==[] or val_lbl==[] or im==[]:\n",
    "            printprint(\"+npz壓縮檔有問題，將由sd19_by_clas夾讀取，並製作npz file\")  \n",
    "        else: \n",
    "            # npz以bitstream 存image，so recovery by the oriange image mode and size \n",
    " \n",
    "            for i in range(len(train_img)):\n",
    "                im1 = Image.new(im['mode'], im['size']) # Create a new image of the same oriange mode and size  \n",
    "                im1.putdata(list(tuple(pixel) for pixel in train_img[i]))  #numpy array to list  \n",
    "                train_img1.append(im1)   \n",
    "                \n",
    "            for i in range(len(val_img)):\n",
    "                im1 = Image.new(im['mode'], im['size']) # Create a new image of the same oriange mode and size \n",
    "                im1.putdata(list(tuple(pixel) for pixel in train_img[i]))  #numpy array to list \n",
    "                val_img1.append(im1)  \n",
    "   \n",
    "            print('成功讀取npz file, training image：'+ str(len(train_img1))+', val_img1:'+str(len(val_img1)))\n",
    "            return train_img1, train_lbl, val_img1, val_lbl, im\n",
    "    except: \n",
    "        print(\"npz壓縮檔不存在，將由sd19_by_clas夾讀取，並製作npz file\")   \n",
    "    '''  \n",
    "\n",
    "\n",
    "        #creat np array of image and label\n",
    "    i=0 \n",
    "    for png in pnglist: \n",
    "        if \"train\" in png:  #the suggested training set for OCR studies\n",
    "            im1=Image.open(png) \n",
    "            im2 = im1.resize((rows, cols), Image.NEAREST)      # use nearest neighbour filter to resize the image(28*28)\n",
    "            im2=np.array(im2) \n",
    "            im2=rgb2gray(im2)  #png 3chanel-> gray 1chanel \n",
    "            train_img=np.vstack((train_img,im2))  #is need:(( ))\n",
    "            i1=png[len(dataPath):len(dataPath)+2] #取出label like '47'   \n",
    "            #train_lbl = np.vstack((train_lbl, chr(int(i1, 16))))  #16進位'47' --> 'G';;training label\n",
    "            train_lbl = np.vstack((train_lbl, int(i1, 16))) #training label;16進位'47'(string) 代表'G'--> 轉成10進位的71,chr(71)-->'G'\n",
    "        elif \"hsf_4\" in png:    #validation data; hsf_4 standard testing set\n",
    "            im1=Image.open(png) \n",
    "            im2 = im1.resize((rows, cols), Image.NEAREST)      # use nearest neighbour filter to resize the image(28*28)\n",
    "            im2=np.array(im2)\n",
    "            im2=rgb2gray(im2)  #png 3chanel-> gray 1chanel\n",
    "            val_img=np.vstack((val_img,im2))  #validation image\n",
    "            i1=png[len(dataPath):len(dataPath)+2] #取出label like '47'    \n",
    "            #val_lbl = np.vstack((val_lbl, chr(int(i1, 16))))  #16進位'47' --> 'G'\n",
    "            val_lbl = np.vstack((val_lbl, int(i1, 16))) #validation label;16進位'47'(string) 代表'G'--> 轉成10進位的71,chr(71)-->'G'\n",
    "        \n",
    "        i +=1\n",
    "        if((i%500)==0):\n",
    "            print('已讀取：'+ str(i) +'---'+png[len(dataPath):len(png)]+'\\r',end='')\n",
    " \n",
    "    if train_img==[] or train_lbl==[] or val_img==[] or val_lbl==[]:\n",
    "        print(\"無資料\")\n",
    "        return 0\n",
    "    #儲存影像,label,image mode & size\n",
    "    print(len(train_lbl),train_lbl.shape, len(train_img),train_img.shape)\n",
    "    #im={'mode':im2.mode,'size':im2.size}\n",
    "    train_img=train_img.reshape((len(train_lbl),28, 28))\n",
    "    train_img=np.delete(train_img, 0,0)  #del 空的初值\n",
    "    train_lbl=np.delete(train_lbl, 0,0)  #del 空的初值\n",
    "    val_img=val_img.reshape((len(val_lbl),28, 28))\n",
    "    val_img=np.delete(val_img, 0,0)  #del 空的初值\n",
    "    val_lbl=np.delete(val_lbl, 0,0)  #del 空的初值\n",
    "    np.savez_compressed(\"train.npz\", train_img=train_img, train_lbl=train_lbl)    \n",
    "    np.savez_compressed(\"val.npz\", val_img=val_img, val_lbl=val_lbl) \n",
    "    print('成功讀取npz file, training image：'+ str(len(train_img))+', val_img1:'+str(len(val_img)))\n",
    "    return train_img, train_lbl, val_img, val_lbl  \n",
    "\n",
    "#將sd19之png images、labe、image mode & size等匯集成list\n",
    "train_img, train_lbl, val_img, val_lbl = prepareData(dataPath, rows, cols)  \n",
    "   \n",
    "tEnd = time.time()#計時結束\n",
    "m, s = divmod((tEnd - tStart), 60) \n",
    "h, m = divmod(m, 60) \n",
    "print('')\n",
    "print (\"it cost: %02d:%02d:%02d\" % (h, m, s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
